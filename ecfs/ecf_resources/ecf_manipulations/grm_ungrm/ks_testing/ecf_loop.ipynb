{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "308e4b25-2886-46d5-8057-4796de25a5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import hist\n",
    "import math\n",
    "import os\n",
    "import json\n",
    "import gc\n",
    "import dask_awkward as dak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb3cc7c7-e8ca-4e2c-9f89-9f4ad1f6f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/scratch365/cmoore24/training/hgg/batch2024/ml_results_checking'\n",
    "with open('../event_totals.json', 'r') as f:\n",
    "    totals = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd4a43e9-f94b-4d81-9afa-57aa4f366d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path}/my_xsecs.json', 'r') as f:\n",
    "    xsecs = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66877873-80f0-47c2-bb90-06949e47ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "xsecs2 = {}\n",
    "for i in xsecs:\n",
    "    if type(xsecs[i]) == dict:\n",
    "        for j in xsecs[i]:\n",
    "            xsecs2[j] = xsecs[i][j]\n",
    "    else:\n",
    "        xsecs2[i] = xsecs[i]\n",
    "xsecs = xsecs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4219228-5986-429d-a816-35099afbadae",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals2 = {}\n",
    "for i in totals:\n",
    "    if type(totals[i]) == dict:\n",
    "        for j in totals[i]:\n",
    "            totals2[f'{i}_{j}'] = totals[i][j]\n",
    "    else:\n",
    "        totals2[i] = totals[i]\n",
    "totals = totals2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7999e930-16d1-4560-a10d-7e5045a7bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(input_path):\n",
    "    if ('.parquet' in os.listdir(input_path)[0]):\n",
    "        output = ak.from_parquet(f'{input_path}/*', columns=columns)\n",
    "    else:\n",
    "        output = {}\n",
    "        for i in os.listdir(input_path):\n",
    "            if ('flat400' not in i):\n",
    "                output[i] = ak.from_parquet(f'{input_path}/{i}/*', columns=columns)\n",
    "            else:\n",
    "                continue\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf20cb0d-f93b-455c-a09d-df2f5d2b3eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals['ww'] = totals['diboson_ww']\n",
    "totals['wz'] = totals['diboson_wz']\n",
    "totals['zz'] = totals['diboson_zz']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99cf500a-7fd8-4fb1-8754-0d3bb77d0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = 'nolepton'\n",
    "path = '/project01/ndcms/cmoore24/skims/full_skims'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a2680cb-0059-471f-91bb-ab3a11ccdbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def firsts(mc):\n",
    "    for i in mc:\n",
    "        if type(mc[i]) == dict:\n",
    "            for j in mc[i]:\n",
    "                for k in mc[i][j].fields:\n",
    "                    if 'event' in k:\n",
    "                        continue\n",
    "                    else:\n",
    "                        try:\n",
    "                            mc[i][j][k] = ak.firsts(mc[i][j][k])\n",
    "                        except:\n",
    "                            continue\n",
    "        else:\n",
    "            for j in mc[i].fields:\n",
    "                if 'event' in j:\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        mc[i][j] = ak.firsts(mc[i][j])\n",
    "                    except:\n",
    "                        continue\n",
    "    return mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fa6c062-4773-4a41-8968-52a16e33bef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ecf_list = dak.from_parquet('/project01/ndcms/cmoore24/skims/full_skims/nolepton/mc/hgg/*').groomed_ecfs.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5fc625a-79a3-44f5-9c57-371ad6c061b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = 1200\n",
    "lower = 500\n",
    "IL = 44.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92315a20-94d7-4815-9ba5-5b70acb71dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecf_hist(dataset, ecf_min, ecf_max, var):\n",
    "    make_hist = hist.Hist.new.Reg(40, ecf_min, ecf_max, name='ECF', label='MC ECF').Weight()\n",
    "    make_hist.fill(ECF=dataset.groomed_ecfs[var])\n",
    "    return make_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb66edc1-7b62-47f5-8eb3-d2d7458d65dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ecf_ks = {}\n",
    "# with open('groomed_ks.json', 'w') as f:\n",
    "#     json.dump(ecf_ks, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "621e0496-e774-4083-b5f2-381a0ba7bd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e2^0.5 is done\n",
      "0\n",
      "1e2^1.0 is done\n",
      "1e2^1.5 is done\n",
      "1e2^2.0 is done\n",
      "1e2^2.5 is done\n",
      "1e2^3.0 is done\n",
      "1e2^3.5 is done\n",
      "1e2^4.0 is done\n",
      "1e3^0.5 is done\n",
      "1e3^1.0 is done\n",
      "1e3^1.5 is done\n",
      "10\n",
      "1e3^2.0 is done\n",
      "1e3^2.5 is done\n",
      "1e3^3.0 is done\n",
      "1e3^3.5 is done\n",
      "1e3^4.0 is done\n",
      "2e3^0.5 is done\n",
      "2e3^1.0 is done\n",
      "2e3^1.5 is done\n",
      "2e3^2.0 is done\n",
      "2e3^2.5 is done\n",
      "20\n",
      "2e3^3.0 is done\n",
      "2e3^3.5 is done\n",
      "2e3^4.0 is done\n",
      "3e3^0.5 is done\n",
      "3e3^1.0 is done\n",
      "3e3^1.5 is done\n",
      "3e3^2.0 is done\n",
      "3e3^2.5 is done\n",
      "3e3^3.0 is done\n",
      "3e3^3.5 is done\n",
      "30\n",
      "3e3^4.0 is done\n",
      "1e4^0.5 is done\n",
      "1e4^1.0 is done\n",
      "1e4^1.5 is done\n",
      "1e4^2.0 is done\n",
      "1e4^2.5 is done\n",
      "1e4^3.0 is done\n",
      "1e4^3.5 is done\n",
      "1e4^4.0 is done\n",
      "2e4^0.5 is done\n",
      "40\n",
      "2e4^1.0 is done\n",
      "2e4^1.5 is done\n",
      "2e4^2.0 is done\n",
      "2e4^2.5 is done\n",
      "2e4^3.0 is done\n",
      "2e4^3.5 is done\n",
      "2e4^4.0 is done\n",
      "3e4^0.5 is done\n",
      "3e4^1.0 is done\n",
      "3e4^1.5 is done\n",
      "50\n",
      "3e4^2.0 is done\n",
      "3e4^2.5 is done\n",
      "3e4^3.0 is done\n",
      "3e4^3.5 is done\n",
      "3e4^4.0 is done\n",
      "4e4^0.5 is done\n",
      "4e4^1.0 is done\n",
      "4e4^1.5 is done\n",
      "4e4^2.0 is done\n",
      "4e4^2.5 is done\n",
      "60\n",
      "4e4^3.0 is done\n",
      "4e4^3.5 is done\n",
      "4e4^4.0 is done\n",
      "5e4^0.5 is done\n",
      "5e4^1.0 is done\n",
      "5e4^1.5 is done\n",
      "5e4^2.0 is done\n",
      "5e4^2.5 is done\n",
      "5e4^3.0 is done\n",
      "5e4^3.5 is done\n",
      "70\n",
      "5e4^4.0 is done\n",
      "6e4^0.5 is done\n",
      "6e4^1.0 is done\n",
      "6e4^1.5 is done\n",
      "6e4^2.0 is done\n",
      "6e4^2.5 is done\n",
      "6e4^3.0 is done\n",
      "6e4^3.5 is done\n",
      "6e4^4.0 is done\n",
      "1e5^0.5 is done\n",
      "80\n",
      "1e5^1.0 is done\n",
      "1e5^1.5 is done\n",
      "1e5^2.0 is done\n",
      "1e5^2.5 is done\n",
      "1e5^3.0 is done\n",
      "1e5^3.5 is done\n",
      "1e5^4.0 is done\n",
      "2e5^0.5 is done\n",
      "2e5^1.0 is done\n",
      "2e5^1.5 is done\n",
      "90\n",
      "2e5^2.0 is done\n",
      "2e5^2.5 is done\n",
      "2e5^3.0 is done\n",
      "2e5^3.5 is done\n",
      "2e5^4.0 is done\n",
      "3e5^0.5 is done\n",
      "3e5^1.0 is done\n",
      "3e5^1.5 is done\n",
      "3e5^2.0 is done\n",
      "3e5^2.5 is done\n",
      "100\n",
      "3e5^3.0 is done\n",
      "3e5^3.5 is done\n",
      "3e5^4.0 is done\n",
      "4e5^0.5 is done\n",
      "4e5^1.0 is done\n",
      "4e5^1.5 is done\n",
      "4e5^2.0 is done\n",
      "4e5^2.5 is done\n",
      "4e5^3.0 is done\n",
      "4e5^3.5 is done\n",
      "110\n",
      "4e5^4.0 is done\n",
      "5e5^0.5 is done\n",
      "5e5^1.0 is done\n",
      "5e5^1.5 is done\n",
      "5e5^2.0 is done\n",
      "5e5^2.5 is done\n",
      "5e5^3.0 is done\n",
      "5e5^3.5 is done\n",
      "5e5^4.0 is done\n",
      "6e5^0.5 is done\n",
      "120\n",
      "6e5^1.0 is done\n",
      "6e5^1.5 is done\n",
      "6e5^2.0 is done\n",
      "6e5^2.5 is done\n",
      "6e5^3.0 is done\n",
      "6e5^3.5 is done\n",
      "6e5^4.0 is done\n",
      "7e5^0.5 is done\n",
      "7e5^1.0 is done\n",
      "7e5^1.5 is done\n",
      "130\n",
      "7e5^2.0 is done\n",
      "7e5^2.5 is done\n",
      "7e5^3.0 is done\n",
      "7e5^3.5 is done\n",
      "7e5^4.0 is done\n",
      "8e5^0.5 is done\n",
      "8e5^1.0 is done\n",
      "8e5^1.5 is done\n",
      "8e5^2.0 is done\n",
      "8e5^2.5 is done\n",
      "140\n",
      "8e5^3.0 is done\n",
      "8e5^3.5 is done\n",
      "8e5^4.0 is done\n",
      "9e5^0.5 is done\n",
      "9e5^1.0 is done\n",
      "9e5^1.5 is done\n",
      "9e5^2.0 is done\n",
      "9e5^2.5 is done\n",
      "9e5^3.0 is done\n",
      "9e5^3.5 is done\n",
      "150\n",
      "9e5^4.0 is done\n",
      "10e5^0.5 is done\n",
      "10e5^1.0 is done\n",
      "10e5^1.5 is done\n",
      "10e5^2.0 is done\n",
      "10e5^2.5 is done\n",
      "10e5^3.0 is done\n",
      "10e5^3.5 is done\n",
      "10e5^4.0 is done\n"
     ]
    }
   ],
   "source": [
    "for k in range(0, len(ecf_list)):\n",
    "    columns=['goodjets.msoftdrop', 'goodjets.pt', (\"groomed_ecfs\", f'{ecf_list[k]}')]\n",
    "    mc = read_files(f'{path}/{region}/mc')\n",
    "    mc['ww'] = mc['diboson_ww']\n",
    "    mc['wz'] = mc['diboson_wz']\n",
    "    mc['zz'] = mc['diboson_zz']\n",
    "    del(mc['diboson_ww'])\n",
    "    del(mc['diboson_wz'])\n",
    "    del(mc['diboson_zz'])\n",
    "    mc = firsts(mc)\n",
    "    data = read_files(f'{path}/{region}/data')\n",
    "    data = firsts(data)\n",
    "\n",
    "    for i in xsecs:\n",
    "        if type(mc[i]) == dict:\n",
    "            for j in mc[i]:\n",
    "                mask = ((mc[i][j].goodjets.pt >= lower) & (mc[i][j].goodjets.pt <= upper))\n",
    "                mc[i][j] = mc[i][j][mask]\n",
    "        else:\n",
    "            mask = ((mc[i].goodjets.pt >= lower) & (mc[i].goodjets.pt <= upper))\n",
    "            mc[i] = mc[i][mask]\n",
    "\n",
    "    for i in data:\n",
    "        if type(data[i]) == dict:\n",
    "            for j in data[i]:\n",
    "                mask = ((data[i][j].goodjets.pt >= lower) & (data[i][j].goodjets.pt <= upper))\n",
    "                data[i][j] = data[i][j][mask]\n",
    "        else:\n",
    "            mask = ((data[i].goodjets.pt >= lower) & (data[i].goodjets.pt <= upper))\n",
    "            data[i] = data[i][mask]\n",
    "\n",
    "    data_s = {}\n",
    "    for i in data:\n",
    "        if \"Jet\" in i:\n",
    "            data_s[i] = data[i]  \n",
    "    data_arr = ak.concatenate([data[i] for i in data_s])\n",
    "\n",
    "    var = ecf_list[k]\n",
    "\n",
    "    ecf_max = ak.max(data_arr.groomed_ecfs[var])\n",
    "    ecf_min = ak.min(data_arr.groomed_ecfs[var])\n",
    "\n",
    "    data_hist = hist.Hist.new.Reg(40, ecf_min, ecf_max, name='ECF', label='Data ECF').Weight()\n",
    "    data_hist.fill(ECF=data_arr.groomed_ecfs[var])\n",
    "\n",
    "    mc2 = {}\n",
    "    for i in xsecs:\n",
    "        if type(mc[i]) == dict:\n",
    "            for j in mc[i]:\n",
    "                mc2[j] = mc[i][j]\n",
    "        else:\n",
    "            mc2[i] = mc[i]\n",
    "    mc = mc2    \n",
    "\n",
    "    hists = {}\n",
    "    for i in mc:\n",
    "        if type(mc[i]) == dict:\n",
    "            hists[i] = {}\n",
    "            for j in mc[i]:\n",
    "                hists[i][j] = msd_hist(mc[i][j])\n",
    "        else:\n",
    "            hists[i] = ecf_hist(mc[i], ecf_min, ecf_max, var)\n",
    "\n",
    "    scaleHgg = ((IL*(xsecs['hgg']*1000)*0.0817)/(totals['hgg']))\n",
    "    hists['hgg'].view(flow=True)[:] *= scaleHgg\n",
    "    \n",
    "    scaleHbb = ((IL*(xsecs['hbb']*1000)*0.581)/(totals['hbb']))\n",
    "    hists['hbb'].view(flow=True)[:] *= scaleHbb\n",
    "\n",
    "    for i in mc:\n",
    "        if (i == 'hgg') or (i == 'hbb'):\n",
    "            continue\n",
    "        else:\n",
    "            scale = ((IL*(xsecs[i]*1000))/(totals[i]))\n",
    "            hists[i].view(flow=True)[:] *= scale\n",
    "\n",
    "    mc_hist = sum(hists[i] for i in hists)\n",
    "\n",
    "    mc_values, mc_bins = mc_hist.to_numpy()\n",
    "    data_values, data_bins = data_hist.to_numpy()\n",
    "    mc_density = mc_values / mc_values.sum()\n",
    "    data_density = data_values / data_values.sum()\n",
    "    mc_cdf = np.cumsum(mc_density)\n",
    "    data_cdf = np.cumsum(data_density)\n",
    "    ks_statistic = np.max(np.abs(mc_cdf - data_cdf))\n",
    "    adjusted = -math.log10(ks_statistic)\n",
    "\n",
    "    with open('groomed_ks.json','r') as f:\n",
    "        ecf_ks = json.load(f)\n",
    "\n",
    "    ecf_ks[var] = adjusted\n",
    "\n",
    "    with open('groomed_ks.json','w') as f:\n",
    "        json.dump(ecf_ks, f)\n",
    "\n",
    "    print(f'{var} is done')\n",
    "    gc.collect()\n",
    "    if k % 10 == 0:\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f97e546-965a-46c9-94f3-3c5e659f8e93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf47d80-fa43-4986-958b-81f7863622b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
